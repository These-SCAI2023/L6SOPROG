{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"150\" src=\"http://lettres.sorbonne-universite.fr/sites/default/files/media/2019-10/sorbonne-lettre_1.svg\"/>\n",
    "\n",
    "\n",
    "# Utiliser spaCy pour la tokenisation, le POtaging et la reconnaissance d'entité nommées\n",
    "## UFR de sociologie et d'informatique pour les sciences humaines\n",
    "### Programmation de Modèles Linguistiques (I)\n",
    "\n",
    "#### Gaël Lejeune et Caroline Koudoro-Parfait\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il faut installer spacy, s'il n'est pas installé décommenter la ligne suivante :\n",
    "\n",
    "https://spacy.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy va utiliser des \"modèles de langue\" pour effectuer les analyses linguistiques.\n",
    "#### Voici un exemple pour télécharger le modèle small (sm) pour le français :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#décommenter la ligne suivante pour charger le modèle de langue :\n",
    "# !python -m spacy download fr_core_news_sm --user\n",
    "#Une fois que le modèle est installé, cette ligne peut être commentée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si le spacy.load ne fonctionne pas :\n",
    "# soit le modèle n'est pas téléchargé, il faut donc reprendre la ligne \"!python -m spacy download...\"\n",
    "# soit il est téléchargé mais notebook ne le trouve pas, il faut juste redémarrer notebook\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je\n",
      "suis\n",
      "un\n",
      "lapin\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Je suis un lapin\"\n",
    "doc = nlp(phrase)\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"Je suis un lapin\"\n",
    "doc = nlp(phrase)\n",
    "for token in doc:\n",
    "    print(token,\"\\t\", token.lemma_,\"\\t\", token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconnaissance d'entité nommées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michelin \t ORG \t\n",
      "New-York \t LOC \t\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Le bonhomme Michelin apparait à New-York\"\n",
    "doc = nlp(phrase)\n",
    "for token in doc.ents:\n",
    "    print(token.text,\"\\t\", token.label_,\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
