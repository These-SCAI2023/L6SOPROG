{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lire_fichier(chemin):\n",
    "  f = open(chemin)\n",
    "  chaine = f.read()\n",
    "  f.close()\n",
    "  return chaine\n",
    "\n",
    "def decouper_en_mots(chaine):\n",
    "  liste_mots = chaine.split()\n",
    "  return liste_mots\n",
    "import os, glob, json\n",
    "try:\n",
    "  os.makedirs(\"Modeles\")\n",
    "except:\n",
    "  pass \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour taille = 1\n",
      "Pour taille = 2\n",
      "Pour taille = 3\n",
      "Pour taille = 4\n"
     ]
    }
   ],
   "source": [
    "for taille in range(1, 5):\n",
    "  print(\"Apprentissage pour taille = %i\"%taille)\n",
    "  if os.path.exists(\"Modeles/models_taille_chaine=%i.json\"):\n",
    "    continue\n",
    "  dic_langues = {}\n",
    "  for chemin in glob.glob(\"corpus_multi/*/appr/*\"):\n",
    "    dossiers = chemin.split(\"/\")#à adapter\n",
    "    langue = dossiers[1]\n",
    "    dic_langues.setdefault(langue, {})#refactor\n",
    "    chaine = lire_fichier(chemin)\n",
    "    for position in range(len(chaine)):\n",
    "      m = chaine[position:position+1+taille]\n",
    "      dic_langues[langue].setdefault(m, 0) #refactor\n",
    "      dic_langues[langue][m] += 1\n",
    "  dic_models = {}\n",
    "  for langue, dic_effectifs in dic_langues.items():\n",
    "    paires = [[effectif, mot] for mot, effectif in  dic_effectifs.items()]\n",
    "    liste_tri = sorted(paires)[-10:]#les 10 chaînes plus fréquentes\n",
    "    dic_models[langue] = [mot for effectif, mot in liste_tri]\n",
    "  w = open(\"Modeles/models_taille_chaine=%i.json\"%taille, \"w\")\n",
    "  w.write(json.dumps(dic_models, indent = 2))\n",
    "  w.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation pour taille = 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f06c6892e10f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation pour taille = %i\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtaille\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Modeles/models_taille_chaine=%i.json\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtaille\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mdic_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mliste_langues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdic_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "dic_courbes = {}#pour faire des courbes ultérieurement\n",
    "for taille in range(1, 5):\n",
    "  print(\"Evaluation pour taille = %i\"%taille)\n",
    "  f = open(\"Modeles/models_taille_chaine=%i.json\"%taille, \"r\")\n",
    "  dic_models = json.load(f)\n",
    "  f.close()\n",
    "  liste_langues = dic_models.keys() \n",
    "  dic_courbes[taille] = {lg : [[], [], []] for lg in liste_langues} \n",
    "  dic_resultats ={lg: {\"VP\":0, \"FP\":0, \"FN\":0} for lg in liste_langues}\n",
    "  for chemin in glob.glob(\"corpus_multi/*/test/*\"):\n",
    "    dossiers = chemin.split(\"/\")\n",
    "    langue = dossiers[1]\n",
    "    chaine = lire_fichier(chemin)\n",
    "    dic_freq_texte = {}\n",
    "    for position in range(len(chaine)):\n",
    "      m = chaine[position:position+1+taille]\n",
    "      dic_freq_texte.setdefault(m, 0) #refactor\n",
    "      dic_freq_texte[m] += 1\n",
    "    paires = [[effectif, mot] for mot, effectif in  dic_freq_texte.items()]\n",
    "    liste_tri = sorted(paires)[-10:]#les 10 chaînes les plus fréquentes\n",
    "    plus_frequents = set([mot for effectif, mot in liste_tri])\n",
    "    liste_predictions = []\n",
    "    for langue_ref, model in dic_models.items():\n",
    "      mots_communs = set(model).intersection(plus_frequents)\n",
    "      liste_predictions.append([len(mots_communs), langue_ref])#refactor\n",
    "    lg_pred = sorted(liste_predictions)[-1][1]#refactor\n",
    "    if lg_pred == langue:\n",
    "      dic_resultats[langue][\"VP\"]+=1\n",
    "    else:\n",
    "      dic_resultats[langue][\"FN\"]+=1\n",
    "      dic_resultats[lg_pred][\"FP\"]+=1\n",
    "  for langue, infos in dic_resultats.items():\n",
    "    VP = infos[\"VP\"]\n",
    "    FP = infos[\"FP\"]\n",
    "    FN = infos[\"FN\"]\n",
    "    if VP!=0:\n",
    "      rappel = VP/(VP+FN)\n",
    "      precision=VP/(VP+FP)\n",
    "      f_mesure = (2*rappel*precision)/(precision+rappel)\n",
    "    else:\n",
    "      rappel, precision, f_mesure = 0, 0, 0\n",
    "    #print(\"%s : rappel =%f, précision=%f et f-mesure=%f\"%(langue,rappel, precision, f_mesure))\n",
    "    dic_courbes[N][langue][0].append(rappel)\n",
    "    dic_courbes[N][langue][1].append(precision)\n",
    "    dic_courbes[N][langue][2].append(f_mesure)\n",
    "\n",
    "w = open(\"resultats_chaines.json\", \"w\")\n",
    "w.write(json.dumps(dic_courbes, indent = 2))\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
