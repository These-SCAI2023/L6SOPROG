{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def lire_fichier(chemin):\n",
    "  with open(chemin, \"r\", encoding=\"utf-8\") as f: \n",
    "    chaine = f.read()\n",
    "  return chaine\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def decouper_en_mots(chaine):\n",
    "  #liste_mots = chaine.split()\n",
    "  liste_mots = word_tokenize(chaine)\n",
    "  return liste_mots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re\n",
    "\n",
    "dic_langues = {}\n",
    "for chemin in glob.glob(\"corpus_multi/*/appr/*\"):\n",
    "  dossiers = chemin.split(\"/\")#Sur Linux/Mac: chemin.split(\"/\")\n",
    "  langue = dossiers[1]\n",
    "  if langue not in dic_langues:\n",
    "    dic_langues[langue] = {}\n",
    "  chaine = lire_fichier(chemin)\n",
    "  mots = chaine.split()\n",
    "  for m in mots:\n",
    "    if m not in dic_langues[langue]:\n",
    "      dic_langues[langue][m] = 1\n",
    "    else:\n",
    "      dic_langues[langue][m] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "dict_keys(['en', 'et', 'it', 'mt', 'pt', 'sk', 'sl', 'bg', 'es', 'da', 'nl', 'lt', 'hu', 'pl', 'fr', 'fi', 'lv', 'el', 'ro', 'sv', 'de', 'cs'])\n",
      "['en', 'et', 'it', 'mt', 'pt', 'sk', 'sl', 'bg', 'es', 'da', 'nl', 'lt', 'hu', 'pl', 'fr', 'fi', 'lv', 'el', 'ro', 'sv', 'de', 'cs']\n"
     ]
    }
   ],
   "source": [
    "print(len(dic_langues))\n",
    "L = dic_langues.keys()\n",
    "print(L)\n",
    "print(list(L))\n",
    "#1/0\n",
    "dic_models = {}\n",
    "for langue, dic_effectifs in dic_langues.items():\n",
    "  paires = [[effectif, mot] for mot, effectif in  dic_effectifs.items()]\n",
    "  liste_tri = sorted(paires)[-10:]#les 10 mots fréquents\n",
    "  dic_models[langue] = [mot for effectif, mot in liste_tri]\n",
    "\n",
    "import json\n",
    "w = open(\"models_nltk.json\", \"w\")\n",
    "w.write(json.dumps(dic_models, indent = 2, ensure_ascii=False))\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitude absolue :  1134\n",
      "Pas de décision :  74\n",
      "Exactitude relative :  0.9204545454545454\n",
      "Exactitude relative filtrée :  0.9792746113989638\n"
     ]
    }
   ],
   "source": [
    "with open(\"models_nltk.json\") as f:\n",
    "    dic_modeles = json.load(f)\n",
    "exactitude = 0\n",
    "Nb_fichiers = len(glob.glob(\"corpus_multi/*/test/*\"))\n",
    "stats = {}\n",
    "stats_pred = {}\n",
    "dic_results = {}\n",
    "pas_decision = 0\n",
    "for chemin in glob.glob(\"corpus_multi/*/test/*\"):\n",
    "    dossiers = chemin.split(\"/\")\n",
    "    langue_reelle = dossiers[1]\n",
    "    if langue_reelle not in dic_results:\n",
    "        dic_results[langue_reelle] = {\"VP\" : 0, \"FP\":0, \"FN\" :0}\n",
    "    stats.setdefault(langue_reelle, 0)\n",
    "    stats[langue_reelle]+=1\n",
    "    chaine = lire_fichier(chemin)\n",
    "    liste_mots = decouper_en_mots(chaine)\n",
    "    dic = {}\n",
    "    for m in liste_mots:\n",
    "        if m not in dic:\n",
    "            dic[m] = 1\n",
    "        else:\n",
    "            dic[m]+=1\n",
    "    paires = []\n",
    "    for mot, effectif in dic.items():\n",
    "        paires.append([effectif, mot])\n",
    "    mots_freq = sorted(paires)[-10:]\n",
    "    mots_OK = []\n",
    "    for effectif, mot in mots_freq:\n",
    "        mots_OK.append(mot)\n",
    "    dic_en_commun = {}\n",
    "    for langue, modele in dic_modeles.items():\n",
    "        mots_en_commun = set(mots_OK).intersection(set(modele))\n",
    "        dic_en_commun[langue] = len(mots_en_commun)\n",
    "    diagnostics = []\n",
    "    for langue, NB_communs in dic_en_commun.items():\n",
    "        diagnostics.append([NB_communs, langue])\n",
    "    langue_predite = sorted(diagnostics)[-1][1]\n",
    "    if sorted(diagnostics)[-1][0]==sorted(diagnostics)[-2][0]:\n",
    "        pas_decision+=1\n",
    "        continue\n",
    "    if langue_predite not in dic_results:\n",
    "        dic_results[langue_predite] = {\"VP\" : 0, \"FP\":0, \"FN\" :0}\n",
    "    if langue_reelle == langue_predite:\n",
    "        exactitude+=1\n",
    "        dic_results[langue_reelle][\"VP\"]+=1\n",
    "    else:\n",
    "        dic_results[langue_reelle][\"FN\"]+=1\n",
    "        dic_results[langue_predite][\"FP\"]+=1\n",
    "    stats_pred.setdefault(langue_predite, 0)\n",
    "    stats_pred[langue_predite]+=1\n",
    "#print(dic_results)\n",
    "#print(stats)\n",
    "#print(stats_pred)\n",
    "\n",
    "print(\"Exactitude absolue : \", exactitude)\n",
    "print(\"Pas de décision : \", pas_decision)\n",
    "print(\"Exactitude relative : \", exactitude/Nb_fichiers)\n",
    "print(\"Exactitude relative filtrée : \", exactitude/(Nb_fichiers-pas_decision))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en \t 1.0 \t 0.718 \t 0.859 \t 0.836\n",
      "et \t 0.875 \t 1.0 \t 0.938 \t 0.933\n",
      "fi \t 0.982 \t 0.902 \t 0.942 \t 0.94\n",
      "it \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "mt \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "pt \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "sk \t 0.982 \t 0.873 \t 0.928 \t 0.924\n",
      "sl \t 0.982 \t 0.982 \t 0.982 \t 0.982\n",
      "bg \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "es \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "da \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "nl \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "lt \t 0.964 \t 1.0 \t 0.982 \t 0.982\n",
      "ro \t 0.982 \t 0.965 \t 0.974 \t 0.973\n",
      "hu \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "pl \t 0.964 \t 1.0 \t 0.982 \t 0.982\n",
      "fr \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "lv \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "el \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "sv \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "de \t 0.982 \t 1.0 \t 0.991 \t 0.991\n",
      "cs \t 0.804 \t 1.0 \t 0.902 \t 0.891\n"
     ]
    }
   ],
   "source": [
    "for langue, dic in dic_results.items():\n",
    "    rappel = dic[\"VP\"]/(dic[\"VP\"]+dic[\"FN\"])\n",
    "    precision=  dic[\"VP\"]/(dic[\"VP\"]+dic[\"FP\"])\n",
    "    F = (2*rappel*precision)/(precision+rappel)\n",
    "    moyenne = (rappel+ precision)/2\n",
    "    print(langue, \"\\t\",round(rappel, 3),\"\\t\", round(precision, 3),\"\\t\",round(moyenne,3), \"\\t\", round(F,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Correction d'une autre manière\n",
    "\n",
    "liste_langues = dic_models.keys() \n",
    "dic_resultats ={lg: {\"VP\":0, \"FP\":0, \"FN\":0} for lg in liste_langues}\n",
    "erreurs= {}\n",
    "for chemin in glob.glob(\"corpus_multi/*/test/*\"):\n",
    "  dossiers = chemin.split(\"/\")\n",
    "  langue = dossiers[1]\n",
    "  chaine = lire_fichier(chemin)\n",
    "  mots = chaine.split()\n",
    "  dic_freq_texte = {}\n",
    "  for m in mots:\n",
    "    if m not in dic_freq_texte:\n",
    "      dic_freq_texte[m] = 1\n",
    "    else:\n",
    "      dic_freq_texte[m] += 1\n",
    "  paires = [[effectif, mot] for mot, effectif in  dic_freq_texte.items()]\n",
    "  liste_tri = sorted(paires)[-10:]#les 10 mots fréquents\n",
    "  plus_frequents = set([mot for effectif, mot in liste_tri])\n",
    "  liste_predictions = []\n",
    "  for langue_ref, model in dic_models.items():\n",
    "    mots_communs = set(model).intersection(plus_frequents)\n",
    "    NB_mots_communs = len(mots_communs)\n",
    "    liste_predictions.append([NB_mots_communs, langue_ref])\n",
    "  liste_predictions = sorted(liste_predictions)\n",
    "  lg_pred = liste_predictions[-1][1]\n",
    "  if lg_pred == langue:\n",
    "    dic_resultats[langue][\"VP\"]+=1\n",
    "  else:\n",
    "    dic_resultats[langue][\"FN\"]+=1\n",
    "    dic_resultats[lg_pred][\"FP\"]+=1\n",
    "    erreurs.setdefault((langue, lg_pred), 0)\n",
    "    erreurs[(langue, lg_pred)] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en : rappel =1.000000, précision=0.717949 et f-mesure=0.835821\n",
      "et : rappel =0.875000, précision=1.000000 et f-mesure=0.933333\n",
      "it : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "mt : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "pt : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "sk : rappel =0.982143, précision=0.873016 et f-mesure=0.924370\n",
      "sl : rappel =0.982143, précision=0.982143 et f-mesure=0.982143\n",
      "bg : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "es : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "da : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "nl : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "lt : rappel =0.964286, précision=1.000000 et f-mesure=0.981818\n",
      "hu : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "pl : rappel =0.964286, précision=1.000000 et f-mesure=0.981818\n",
      "fr : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "fi : rappel =0.982143, précision=0.901639 et f-mesure=0.940171\n",
      "lv : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "el : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "ro : rappel =0.982143, précision=0.964912 et f-mesure=0.973451\n",
      "sv : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "de : rappel =0.982143, précision=1.000000 et f-mesure=0.990991\n",
      "cs : rappel =0.803571, précision=1.000000 et f-mesure=0.891089\n",
      "Pour la paire ('et', 'fi') : 6 erreurs\n",
      "Pour la paire ('et', 'en') : 1 erreurs\n",
      "Pour la paire ('it', 'en') : 1 erreurs\n",
      "Pour la paire ('mt', 'en') : 1 erreurs\n",
      "Pour la paire ('pt', 'en') : 1 erreurs\n",
      "Pour la paire ('sk', 'en') : 1 erreurs\n",
      "Pour la paire ('sl', 'en') : 1 erreurs\n",
      "Pour la paire ('bg', 'en') : 1 erreurs\n",
      "Pour la paire ('es', 'en') : 1 erreurs\n",
      "Pour la paire ('da', 'en') : 1 erreurs\n",
      "Pour la paire ('nl', 'en') : 1 erreurs\n",
      "Pour la paire ('lt', 'ro') : 1 erreurs\n",
      "Pour la paire ('lt', 'en') : 1 erreurs\n",
      "Pour la paire ('hu', 'en') : 1 erreurs\n",
      "Pour la paire ('pl', 'en') : 1 erreurs\n",
      "Pour la paire ('pl', 'ro') : 1 erreurs\n",
      "Pour la paire ('fr', 'en') : 1 erreurs\n",
      "Pour la paire ('fi', 'en') : 1 erreurs\n",
      "Pour la paire ('lv', 'en') : 1 erreurs\n",
      "Pour la paire ('el', 'en') : 1 erreurs\n",
      "Pour la paire ('ro', 'en') : 1 erreurs\n",
      "Pour la paire ('sv', 'en') : 1 erreurs\n",
      "Pour la paire ('de', 'en') : 1 erreurs\n",
      "Pour la paire ('cs', 'en') : 2 erreurs\n",
      "Pour la paire ('cs', 'sk') : 8 erreurs\n",
      "Pour la paire ('cs', 'sl') : 1 erreurs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for langue, infos in dic_resultats.items():\n",
    "  VP = infos[\"VP\"]\n",
    "  FP = infos[\"FP\"]\n",
    "  FN = infos[\"FN\"]\n",
    "  if VP!=0:\n",
    "    rappel = VP/(VP+FN)\n",
    "    precision=VP/(VP+FP)\n",
    "    f_mesure = (2*rappel*precision)/(precision+rappel)\n",
    "  else:\n",
    "    rappel, precision, f_mesure = 0, 0, 0\n",
    "  print(\"%s : rappel =%f, précision=%f et f-mesure=%f\"%(langue,rappel, precision, f_mesure))\n",
    "\n",
    "for paire, NB_erreurs in erreurs.items():\n",
    "  print(\"Pour la paire %s : %i erreurs\"%(str(paire), NB_erreurs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
