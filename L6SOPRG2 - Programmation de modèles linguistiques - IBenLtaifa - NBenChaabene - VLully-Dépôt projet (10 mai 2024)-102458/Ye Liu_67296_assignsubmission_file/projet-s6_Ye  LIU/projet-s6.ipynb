{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5fa8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS:\n",
    "import glob\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24590dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FONCTIONS pour modèle:\n",
    "def supprimer_ponctuation (ligne_brut):\n",
    "    ponc=r'[^\\w\\s]|[\\t\\n\\d+]'\n",
    "    ligne=re.sub(ponc, '', ligne_brut)\n",
    "    return ligne\n",
    "#==#phrase = phrase.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "def lire_fichier(label, chemin):\n",
    "    lignes=[]   \n",
    "    labels=[]\n",
    "    \n",
    "    with open (chemin, 'r',encoding='utf-8')as f:\n",
    "        ligne_brut=f.readline()\n",
    "        \n",
    "        while ligne_brut:\n",
    "            ligne=supprimer_ponctuation (ligne_brut)\n",
    "            #ligne=ligne_brut.translate(str.maketrans('','',string.punctuation))\n",
    "            ligne=ligne.lower()\n",
    "            ligne=ligne.rstrip()\n",
    "            \n",
    "            \n",
    "            lignes.append (ligne)\n",
    "            labels.append (label)\n",
    "        \n",
    "            ligne_brut=f.readline()           \n",
    "            \n",
    "    return lignes,labels\n",
    "\n",
    "\n",
    "def predire_auteur(phz):    \n",
    "    phz=supprimer_ponctuation(phz)\n",
    "    phz=phz.lower()\n",
    "    phz=phz.rstrip()\n",
    "    \n",
    "    X_phz=vec.transform([phz])\n",
    "    pred=model.predict(X_phz)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b4df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluer_modele_2(predicitions,Ytest):# 2 classes \n",
    "    #comptage:\n",
    "    f={'vp':0,'vn':0,'fn':0,'fp':0} \n",
    "    for p, y in zip(predictions, Ytest):\n",
    "        if p==1:#apo=0,bau=1\n",
    "            if p==y:\n",
    "                f['vp']+=1\n",
    "            else :#p!=y\n",
    "                f['fp']+=1\n",
    "        else :#p==0\n",
    "            if p==y:\n",
    "                f['vn']+=1\n",
    "            else :#p!=y\n",
    "                f['fn']+=1\n",
    "    #print (f) #meme fonction que cm!\n",
    "    \n",
    "    #calcul:\n",
    "    vp=f['vp']\n",
    "    fn=f['fn']\n",
    "    fp=f['fp']\n",
    "    rappel=vp/(vp+fn)\n",
    "    precision=vp/(vp+fp)\n",
    "    f_mesure=2*rappel*precision/(rappel+precision)\n",
    "    \n",
    "    return f, f_mesure #0.6153846153846153\n",
    "\n",
    "\n",
    "\n",
    "def evaluer_modele_(predictions,corpus):#classes>2\n",
    "    #initialiser un dictionnaire pour stocker le résultat \n",
    "    precisions={}#initialiser un dicto \n",
    "    label2auteur={}\n",
    "    for label, chemin in enumerate(corpus):\n",
    "        auteur = auteur=chemin.split(\"//\")[1].split('.')[0]\n",
    "        label2auteur[label]=auteur\n",
    "        if auteur not in precisions :\n",
    "            precisions[auteur]={'vp':0,'fn':0,'fp':0} \n",
    "    #print (label2auteur)\n",
    "    #print (precisions)\n",
    "    \n",
    "    #compter vp, fn; fp:\n",
    "    b=0\n",
    "    for label, pred in zip(Ytest, predictions):\n",
    "        \n",
    "        label=str(label)\n",
    "        pred=np.array2string(pred) #convertit le vecteur en intégral\n",
    "        #print (label, pred)\n",
    "        \n",
    "        if label==pred:#bonne prédiction\n",
    "            b+=1\n",
    "            #print ('bonne prédiction')\n",
    "            auteur=label2auteur[int(label)]#label a été transformé en str!        \n",
    "            precisions[auteur]['vp']+=1\n",
    "            \n",
    "        else :#label!=pred #mauvaise prédiction \n",
    "            auteur=label2auteur[int(label)]\n",
    "            auteur_pred=label2auteur[int(pred)]\n",
    "            precisions[auteur]['fn']+=1\n",
    "            precisions[auteur_pred]['fp']+=1\n",
    "    \n",
    "    #print (\"nb de bonnes prédictions: \", b)\n",
    "    #print (precisions)\n",
    "    \n",
    "    f_mesure={}\n",
    "    for auteur,subdic in precisions.items():\n",
    "        vp=subdic['vp']\n",
    "        fn=subdic['fn']\n",
    "        fp=subdic['fp']\n",
    "        \n",
    "        rappel=vp/(vp+fn)\n",
    "        precision=vp/(vp+fp)\n",
    "        f=2*rappel*precision/(rappel+precision)\n",
    "            \n",
    "        if auteur not in f_mesure:\n",
    "            f_mesure[auteur]={}\n",
    "        f_mesure[auteur]={'rappel':rappel,'précision':precision,'f-mesure':f}\n",
    "    \n",
    "    \n",
    "    return precisions, f_mesure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f49b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODES :\n",
    "#1.Préparer le corpus:\n",
    "\n",
    "#corpus=['corpus_1000//apollinaire.txt', 'corpus_1000//baudelaire.txt']\n",
    "corpus=['corpus_1600//apollinaire.txt', 'corpus_1600//baudelaire.txt']\n",
    "#corpus=['corpus_1600//apollinaire.txt', 'corpus_1600//baudelaire.txt', 'corpus_1600//valery.txt']\n",
    "#corpus=['corpus_1600//apollinaire.txt', 'corpus_1600//baudelaire.txt', 'corpus_1600//valery.txt', 'corpus_1600//prevert.txt']\n",
    "#corpus=['corpus_3000//baudelaire.txt', 'corpus_3000//apollinaire.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2cad042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apollinaire:265\n",
      "baudelaire:222\n",
      "487\n",
      "487\n"
     ]
    }
   ],
   "source": [
    "#2.Prétraitement du corpus :lire+nettoyer \n",
    "corpus_poeme=[]\n",
    "labels_poeme=[]\n",
    "for label, chemin in enumerate(corpus):    \n",
    "    #print (chemin)\n",
    "    auteur=chemin.split(\"//\")[1].split('.')[0]\n",
    "    #print (f'{auteur}:{label}')\n",
    "    \n",
    "    lignes,labels=lire_fichier(label, chemin)    \n",
    "    print (f'{auteur}:{len(lignes)}')\n",
    "    \n",
    "    corpus_poeme.extend(lignes)\n",
    "    labels_poeme.extend(labels)\n",
    "print (len(corpus_poeme))\n",
    "print (len(labels_poeme))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d079ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n",
      "147\n",
      "['fautil quil men souvienne', 'devant ce noir tableau plein dépouvantement', '']\n",
      "[0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#division du corpus:    \n",
    "train_text, test_text, Ytrain, Ytest=train_test_split(corpus_poeme, labels_poeme,test_size=0.30,random_state=42)\n",
    "print(len(train_text))\n",
    "print (len(test_text))\n",
    "print (train_text[:3])\n",
    "print (Ytrain[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd1691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Convertir le texte en vecteur :\n",
    "#vec=TfidfVectorizer(decode_error='ignore')\n",
    "vec=CountVectorizer(decode_error='ignore')\n",
    "\n",
    "Xtrain=vec.fit_transform(train_text)\n",
    "Xtest=vec.transform(test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "206aa324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.Entraîner le modèle\n",
    "model=MultinomialNB()#charger le modèle\n",
    "#model=AdaBoostClassifier() \n",
    "model.fit(Xtrain, Ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e3f967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#5. Appliquer le modèle : prédictions\n",
    "#demo :\n",
    "#phz=\"Il faisait des enfants la joie et la risée.\"\n",
    "phz='Et jamais je ne pleure et jamais je ne ris.'\n",
    "pred =predire_auteur(phz)\n",
    "print (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43723390",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(Xtest)\n",
    "# print (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa85d9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vp': 43, 'vn': 67, 'fn': 22, 'fp': 15}\n",
      "f_mesure: 0.6991869918699186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. évaluer le modèle \n",
    "#1)calcule manuellement : pas satisfaisant \n",
    "#2classes:\n",
    "f,f_mesure=evaluer_modele_2(predictions, Ytest)\n",
    "print(f)\n",
    "print ('f_mesure:',f_mesure)\n",
    "\n",
    "#plus de 2classes :\n",
    "#compter manuellement vp, fp,fn\n",
    "# precisions, f_mesure_=evaluer_modele_(predictions,corpus)\n",
    "# print (precisions)\n",
    "# print(f_mesure_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "044e5a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67 15]\n",
      " [22 43]]\n",
      "report de modèle:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78        82\n",
      "           1       0.74      0.66      0.70        65\n",
      "\n",
      "    accuracy                           0.75       147\n",
      "   macro avg       0.75      0.74      0.74       147\n",
      "weighted avg       0.75      0.75      0.75       147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2) calcule automatiquement : plus juste\n",
    "cm_test=confusion_matrix(Ytest, predictions)\n",
    "print (cm_test)\n",
    "\n",
    "#f1_score_=f1_score(Ytest, predictions)\n",
    "#print ('f1_score_test:',f1_score_)#==f_mesure/f_mesure_\n",
    "# #^seulment pour clf de 2classes\n",
    "\n",
    "#3)calcule automatiquement\n",
    "print ('report de modèle:')    \n",
    "print (classification_report(Ytest,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d55355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a100f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##EXTRA : \n",
    "#FONCTIONS pour le classificateur Markov\n",
    "def mapping (corpus):\n",
    "    idx=0\n",
    "    word2idx={}\n",
    "    for l in corpus:#train_text? ou tout le corpus\n",
    "        for m in l.split(' '):\n",
    "            if m not in word2idx:\n",
    "                word2idx[m]=idx\n",
    "                idx+=1\n",
    "    return word2idx\n",
    "    #print(word2idx)#1800 pour train_text, 2335 pour corpus\n",
    "\n",
    "\n",
    "\n",
    "def word_to_int(texte,word2idx):\n",
    "    texte_int=[]\n",
    "    for l in texte:\n",
    "        l_int=[]\n",
    "        mots=l.split(' ')\n",
    "        for m in mots :\n",
    "            idx=word2idx[m]\n",
    "            l_int.append (idx)\n",
    "        texte_int.append (l_int)\n",
    "    return texte_int\n",
    "\n",
    "\n",
    "    \n",
    "def compute_counts (train_text_int, A, pi):#transforme les idx en transitions\n",
    "    for l in train_text_int:#train_text_int est le texte en idx, selon le word2idx\n",
    "        #print (l)\n",
    "        for i, idx in enumerate(l):\n",
    "            if i == 0:#initial\n",
    "                if idx not in pi:\n",
    "                    pi[idx]=1#compter freq de premier mot?\n",
    "                else :\n",
    "                    pi[idx]+=1\n",
    "                   \n",
    "            else :\n",
    "                last_idx=l[i-1]\n",
    "                A[last_idx,idx]+=1 #compte la transition\n",
    "                \n",
    "    return A, pi\n",
    "\n",
    "\n",
    "def normaliser (A, pi):#transforme la transition en pourcentage \n",
    "    #A:\n",
    "    for y, l in enumerate(A):#y = axe y, l= ligne\n",
    "        #print (y)\n",
    "        som=sum(l)\n",
    "        #print (som)#2662\n",
    "\n",
    "        for x,freq in enumerate (l) :\n",
    "            p = freq /som\n",
    "            A[y,x]=p \n",
    "        #break \n",
    "            \n",
    "    #pi:\n",
    "    somme=sum(pi)\n",
    "    #print (som)#2538\n",
    "    for y, freq in enumerate(pi):\n",
    "        p=freq/somme\n",
    "        pi[y]=p\n",
    "    \n",
    "    return A,pi\n",
    "\n",
    "\n",
    "def etablir_matrice(word2idx,train_text_int,Ytrain,label):\n",
    "    v=len(word2idx)\n",
    "    A0=np.ones((v,v))#établir une matrice, rempli par 1\n",
    "    pi0=np.ones(v)\n",
    "    \n",
    "    A0, pi0=compute_counts([l for l, lab in zip(train_text_int,Ytrain) if lab==label], A0, pi0)\n",
    "    A0, pi0=normaliser(A0, pi0)\n",
    "    logA0=np.log(A0)\n",
    "    logpi0=np.log(pi0)\n",
    "    \n",
    "    count0=[y for y in Ytrain if y==label]\n",
    "    p0=len(count0)/len(Ytrain) #prior:0.43188854489164086 #pq sum(y==0)??\n",
    "    logp0=np.log(p0)\n",
    "    \n",
    "    return logA0,logpi0,logp0\n",
    "\n",
    "\n",
    "\n",
    "def classifier(input_int,logA,logPI,logP):\n",
    "    k=len(logP)\n",
    "    \n",
    "    predictions=np.zeros(len(input_int))#établir une matrice pour stocker le résultat\n",
    "\n",
    "    for i_l,l in enumerate(input_int):\n",
    "             \n",
    "        #calculer dans une matrice, la pb que cette ligne_int peut accumuler \n",
    "        pb=[]#pour stocker la pb obtenu sur la base de matrice diff\n",
    "        for c in range (k):\n",
    "            loga=logA[c]\n",
    "            logpi=logPI[c]\n",
    "            logp=logP[c]\n",
    "            \n",
    "            logpb=0\n",
    "            for i, idx in enumerate(l) :#accumuler toutes les pb qu'une idx à l'autre dans cet input\n",
    "                #print (i,idx)\n",
    "                if i==0:#si initial\n",
    "                    logpb+=logpi[idx]\n",
    "                    #print (i,idx,logpi[idx])\n",
    "                    #print (logpb)#\n",
    "                    \n",
    "                else :\n",
    "                    #print(i,idx)\n",
    "                    last_idx=l[i-1]\n",
    "                    #print(last_idx)\n",
    "                    \n",
    "                    logpb+=loga[last_idx,idx]\n",
    "                    #print (loga[last_idx,idx])\n",
    "            #print (c,logpb)#la valeur plus petite, la pb originale plus grande\n",
    "            pb.append(logpb+logp)#selon la loi naive_bayes\n",
    "        \n",
    "        #sélectionner la pb plus grande\n",
    "        pb_max=max(pb)#?????min?\n",
    "        idx_max=pb.index(pb_max)\n",
    "        #print(idx_max)\n",
    "        predictions[i_l]=idx_max\n",
    "        \n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19052aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODES : MARKOV\n",
    "#1.mapping :\n",
    "word2idx=mapping(corpus_poeme)\n",
    "train_text_int=word_to_int(train_text, word2idx)\n",
    "test_text_int=word_to_int(test_text,word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "102fdc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#etablir les matrices :\n",
    "#2 classes :\n",
    "logA0,logpi0,logp0=etablir_matrice(word2idx,train_text_int,Ytrain,0)\n",
    "logA1,logpi1,logp1=etablir_matrice(word2idx,train_text_int,Ytrain,1)\n",
    "logA=[logA0, logA1]\n",
    "logPI=[logpi0, logpi0]\n",
    "logP=[logp0, logp1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ce82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 classes:\n",
    "# logA0,logpi0,logp0=etablir_matrice(word2idx,train_text_int,Ytrain,0)\n",
    "# logA1,logpi1,logp1=etablir_matrice(word2idx,train_text_int,Ytrain,1)\n",
    "# logA2,logpi2,logp2=etablir_matrice(word2idx,train_text_int,Ytrain,2)\n",
    "# logA=[logA0, logA1,logA2]\n",
    "# logPI=[logpi0, logpi0,logpi2]\n",
    "# logP=[logp0, logp1,logp2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cfe328d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auteur de input: [1.]\n"
     ]
    }
   ],
   "source": [
    "#2.Appliquer le classificateur:\n",
    "#demo:\n",
    "#input_=\"L'amour s'en va comme cette eau courante\"#apo=0\n",
    "input_=\"L’Enfant déshérité s’enivre de soleil,\"#bau=1\n",
    "input_=supprimer_ponctuation(input_)\n",
    "input_=input_.lower()\n",
    "input_=input_.rstrip()\n",
    "input_int=word_to_int([input_], word2idx)\n",
    "\n",
    "input_p=classifier(input_int,logA,logPI,logP)\n",
    "print ('auteur de input:',input_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3995c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tester le corpus :\n",
    "Ptrain=classifier(train_text_int,logA,logPI,logP)\n",
    "acc_train=np.mean(Ptrain==Ytrain)\n",
    "#print ('train:',acc_train)\n",
    "\n",
    "Ptest=classifier(test_text_int,logA,logPI,logP)\n",
    "acc_test=np.mean(Ptest==Ytest)\n",
    "#print ('test:',acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "831d3941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183   0]\n",
      " [  9 148]]\n",
      "[[79  3]\n",
      " [40 25]]\n",
      "report de clf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.79        82\n",
      "           1       0.89      0.38      0.54        65\n",
      "\n",
      "    accuracy                           0.71       147\n",
      "   macro avg       0.78      0.67      0.66       147\n",
      "weighted avg       0.77      0.71      0.68       147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.évaluer le modèle :\n",
    "#Comptage de vp n:\n",
    "cm_train=confusion_matrix(Ytrain, Ptrain)\n",
    "print (cm_train)\n",
    "cm_test=confusion_matrix(Ytest,Ptest)\n",
    "print (cm_test)\n",
    "\n",
    "    \n",
    "#3)calcule automatiquement\n",
    "print ('report de clf:')    \n",
    "print (classification_report(Ytest,Ptest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138faf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b24d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
